#!/usr/bin/env python3
"""
Quick test to verify data files are available and loadable.

Run this before running validate_y_actual_binning.py to ensure data is available.
"""

from pathlib import Path
import pandas as pd
from data_processing import build_conformal_totals_df

def main():
    print("="*70)
    print("Data Loading Test")
    print("="*70)

    data_dir = Path(__file__).parent / "data"
    actuals_path = data_dir / "actuals_filtered_rts3_constellation_v1.parquet"
    forecasts_path = data_dir / "forecasts_filtered_rts3_constellation_v1.parquet"

    print(f"\nChecking data directory: {data_dir}")
    print(f"  Exists: {data_dir.exists()}")

    print(f"\nChecking actuals file: {actuals_path.name}")
    print(f"  Exists: {actuals_path.exists()}")
    if actuals_path.exists():
        print(f"  Size: {actuals_path.stat().st_size / 1024 / 1024:.2f} MB")

    print(f"\nChecking forecasts file: {forecasts_path.name}")
    print(f"  Exists: {forecasts_path.exists()}")
    if forecasts_path.exists():
        print(f"  Size: {forecasts_path.stat().st_size / 1024 / 1024:.2f} MB")

    if not actuals_path.exists() or not forecasts_path.exists():
        print("\n" + "="*70)
        print("ERROR: Data files not found!")
        print("="*70)
        print("\nPlease ensure the following files exist:")
        print(f"  {actuals_path}")
        print(f"  {forecasts_path}")
        print("\nThese files should be generated by the covariance pipeline.")
        return 1

    print("\n" + "="*70)
    print("Loading data...")
    print("="*70)

    try:
        actuals = pd.read_parquet(actuals_path)
        print(f"\n(ok) Actuals loaded: {len(actuals)} rows, {len(actuals.columns)} columns")
        print(f"  Columns: {actuals.columns.tolist()[:5]}...")

        forecasts = pd.read_parquet(forecasts_path)
        print(f"\n(ok) Forecasts loaded: {len(forecasts)} rows, {len(forecasts.columns)} columns")
        print(f"  Columns: {forecasts.columns.tolist()[:5]}...")

        df_tot = build_conformal_totals_df(actuals, forecasts)
        print(f"\n(ok) Conformal totals built: {len(df_tot)} time points")
        print(f"  Columns: {df_tot.columns.tolist()}")
        print(f"\n  Sample data (first 3 rows):")
        print(df_tot[["y", "ens_mean", "ens_std"]].head(3).to_string())

        # Check for required columns
        required_cols = ["y", "ens_mean", "ens_std", "TIME_HOURLY"]
        missing = [c for c in required_cols if c not in df_tot.columns]
        if missing:
            print(f"\n(x) ERROR: Missing required columns: {missing}")
            return 1

        print("\n" + "="*70)
        print("SUCCESS - Data is ready!")
        print("="*70)
        print("\nYou can now run:")
        print("  python validate_y_actual_binning.py")
        return 0

    except Exception as e:
        print(f"\n(x) ERROR loading data: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())
